include: config/model/ad_base.yaml

model: CompressedAD

# AD Transformer - larger for more complex task (key-to-door)
# With n_transit=80 and n_compress_tokens=20:
#   - Available space after compression: 80 - 20 - 1 = 59 tokens
#   - Compression triggers every ~59 new transitions
tf_n_embd: 64
tf_n_layer: 4
tf_n_head: 4
tf_dropout: 0.1
tf_attn_dropout: 0.1
tf_n_inner: 128         # 4x embedding dim
n_transit: 60           # Larger context for more complex task

# Compression Settings
n_compress_tokens: 16   # More tokens to capture key+door info
compress_n_layers: 3
compress_n_heads: 4

# Gradient control
max_gradient_rounds: 99999

# Reconstruction regularization
use_recon_reg: True
recon_reg_weight: 0.5

# Reward-weighted reconstruction (during fine-tuning)
# Gives higher weight to transitions with positive rewards (key-finding and door-reaching)
use_reward_weighted_recon: False
reward_weight_multiplier: 0.0

# Curriculum settings (None = unlimited)
max_compressions: null

# Dataset settings
# With n_transit=80, compression triggers at ~59 steps
min_context_length: 30
max_context_length: 1500

# Curriculum with stage-specific length distributions
curriculum_schedule:
  - step: 0
    max_compressions: 1
    length_distribution:
      short: 0.60
      medium: 0.35
      long: 0.05
      very_long: 0.00
  - step: 30000
    max_compressions: 3
    length_distribution:
      short: 0.35
      medium: 0.40
      long: 0.20
      very_long: 0.05
  - step: 60000
    max_compressions: 6
    length_distribution:
      short: 0.25
      medium: 0.30
      long: 0.30
      very_long: 0.15
  - step: 80000
    max_compressions: null
    length_distribution:
      short: 0.25
      medium: 0.25
      long: 0.25
      very_long: 0.25

# Training
lr: 0.0003
train_batch_size: 128
test_batch_size: 256
train_source_timesteps: 2000
train_timesteps: 120000
num_warmup_steps: 2000

# Curriculum-aware LR scheduler settings
stage_warmup_steps: 500
min_lr_ratio: 0.1

# Best model tracking
save_best_model: True
early_stopping_patience: 10

num_workers: 4
