include: config/model/ad_base.yaml

model: CompressedAD

# AD Transformer
tf_n_embd: 64
tf_n_layer: 4
tf_n_head: 4
tf_dropout: 0.1
tf_attn_dropout: 0.1
tf_n_inner: 128
n_transit: 240  

# Compression Settings
n_compress_tokens: 64   
compress_n_layers: 3    
compress_n_heads: 8     

# Gradient control
max_gradient_rounds: 2

# Reconstruction regularization during fine-tuning
use_recon_reg: True
recon_reg_weight: 0.1

# Curriculum settings (None = unlimited)
max_compressions: null

# Dataset settings - adjusted for available 1040 timestep data
min_context_length: 50
max_context_length: 1000

# Balanced length distribution for 1040-step dataset
# Emphasize short/medium to ensure solid AD learning first
length_distribution:
  short: 0.30      # No compression: 50-200 (most important for base learning)
  medium: 0.30     # 1 compression: 250-400 
  long: 0.25       # 2-3 compressions: 450-700
  very_long: 0.15  # 3-4 compressions: 750-1000

# Training
lr: 0.0003  
train_batch_size: 64  # Reduced to avoid OOM with variable-length sequences
test_batch_size: 128
train_source_timesteps: 1000  # Match available data
train_timesteps: 100000
num_warmup_steps: 1000  

num_workers: 4

# Curriculum - gradual progression
curriculum_schedule:
  - step: 0
    max_compressions: 1
  - step: 15000
    max_compressions: 2
  - step: 35000
    max_compressions: 3
  - step: 60000
    max_compressions: null  # Unlimited
